{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infrared-campus",
   "metadata": {},
   "source": [
    "## Predict BMI\n",
    "\n",
    "In this example, we will constrain the infinite set of different analyses to investigating how a few different analytic choices will vary performance when predicting subjects BMI.\n",
    "\n",
    "1. Using vertex data directly as input to a ridge regression\n",
    "2. Apply both a pre-existing parcellation and a randomly generated parcellation to the data to the data, then try two ML models, an elastic-net regression and a SVM.\n",
    "3. Test ensembles over over randomly generated parcellations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continent-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import BPt as bp\n",
    "import os\n",
    "from os.path import dirname, abspath\n",
    "import numpy as np\n",
    "from neurotools.transform.rois import SurfLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heated-focus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "        <h3>Data</h3><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>thickness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0001</th>\n",
       "      <td>Loc(1484)</td>\n",
       "      <td>Loc(556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0002</th>\n",
       "      <td>Loc(1736)</td>\n",
       "      <td>Loc(808)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0003</th>\n",
       "      <td>Loc(1211)</td>\n",
       "      <td>Loc(283)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0004</th>\n",
       "      <td>Loc(1748)</td>\n",
       "      <td>Loc(820)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0005</th>\n",
       "      <td>Loc(1240)</td>\n",
       "      <td>Loc(312)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0924</th>\n",
       "      <td>Loc(1743)</td>\n",
       "      <td>Loc(815)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0925</th>\n",
       "      <td>Loc(1372)</td>\n",
       "      <td>Loc(444)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0926</th>\n",
       "      <td>Loc(1483)</td>\n",
       "      <td>Loc(555)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0927</th>\n",
       "      <td>Loc(1391)</td>\n",
       "      <td>Loc(463)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0928</th>\n",
       "      <td>Loc(1774)</td>\n",
       "      <td>Loc(846)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 2 columns</p>\n",
       "</div></div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "        <h3>Targets</h3><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIS</th>\n",
       "      <th>BMI</th>\n",
       "      <th>IST_intelligence_total</th>\n",
       "      <th>NEO_N</th>\n",
       "      <th>STAI_T</th>\n",
       "      <th>age</th>\n",
       "      <th>education_level</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0001</th>\n",
       "      <td>16</td>\n",
       "      <td>23.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>28</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0002</th>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0003</th>\n",
       "      <td>20</td>\n",
       "      <td>31.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>34</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0004</th>\n",
       "      <td>22</td>\n",
       "      <td>20.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>29</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0005</th>\n",
       "      <td>20</td>\n",
       "      <td>23.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>27</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0924</th>\n",
       "      <td>22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>40</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0925</th>\n",
       "      <td>13</td>\n",
       "      <td>30.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>28</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0926</th>\n",
       "      <td>20</td>\n",
       "      <td>22.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0927</th>\n",
       "      <td>23</td>\n",
       "      <td>35.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>35</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0928</th>\n",
       "      <td>21</td>\n",
       "      <td>19.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>30</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 8 columns</p>\n",
       "</div></div>\n"
      ],
      "text/plain": [
       "                 BMI  IST_intelligence_total    age sex education_level  \\\n",
       "participant_id                                                            \n",
       "sub-0001        23.0                   159.0  22.00   0               2   \n",
       "sub-0002        20.0                   199.0  21.75   0               2   \n",
       "sub-0003        31.0                   227.0  25.25   0               0   \n",
       "sub-0004        20.0                   270.0  22.50   0               0   \n",
       "sub-0005        23.0                   212.0  22.25   1               0   \n",
       "...              ...                     ...    ...  ..             ...   \n",
       "sub-0924        21.0                   246.0  22.25   1               2   \n",
       "sub-0925        30.0                   150.0  25.25   1               2   \n",
       "sub-0926        22.0                   161.0  20.75   1               0   \n",
       "sub-0927        35.0                   190.0  24.25   0               2   \n",
       "sub-0928        19.0                   243.0  20.50   1               0   \n",
       "\n",
       "                STAI_T  BIS  NEO_N  thickness    area  \n",
       "participant_id                                         \n",
       "sub-0001          44.0   16     28      556.0  1484.0  \n",
       "sub-0002          31.0   20     30      808.0  1736.0  \n",
       "sub-0003          40.0   20     34      283.0  1211.0  \n",
       "sub-0004          32.0   22     29      820.0  1748.0  \n",
       "sub-0005          23.0   20     27      312.0  1240.0  \n",
       "...                ...  ...    ...        ...     ...  \n",
       "sub-0924          56.0   22     40      815.0  1743.0  \n",
       "sub-0925          44.0   13     28      444.0  1372.0  \n",
       "sub-0926          30.0   20     27      555.0  1483.0  \n",
       "sub-0927          38.0   23     35      463.0  1391.0  \n",
       "sub-0928          37.0   21     30      846.0  1774.0  \n",
       "\n",
       "[928 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Useful directories\n",
    "main_dr = dirname(abspath(os.getcwd()))\n",
    "data_dr = os.path.join(main_dr, 'data')\n",
    "\n",
    "# This is optional, but speeds up some\n",
    "# operations, to ignore, set to None\n",
    "cache_loc = os.path.join(data_dr, 'cache', 'fs_surf')\n",
    "\n",
    "# Load in our pre-saved dataset\n",
    "data = bp.read_pickle(os.path.join(data_dr, 'datasets', 'fs_surf.dataset'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-number",
   "metadata": {},
   "source": [
    "Below are some utilities that will make the code easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "popular-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_search_model(model_str, params=1):\n",
    "    '''We define our base model here as a model\n",
    "    with nested random hyper-parameter search\n",
    "    used to choose across values (params=1 means we are\n",
    "    using default hyper-parameter e.g., distribution 1,\n",
    "    see: https://sahahn.github.io/BPt/options/pipeline_options/models.html#ridge-regressor\n",
    "    '''\n",
    "    \n",
    "    random_search = bp.ParamSearch('RandomSearch', n_iter=60)\n",
    "    return bp.Model(model_str, params=params, param_search=random_search)\n",
    "\n",
    "\n",
    "def load_parcel(parcel_name):\n",
    "    '''This function is designed to load and save pre-generated\n",
    "    parcellations from a different project. We use it here as a helper.'''\n",
    "    \n",
    "    # Make sure parcel directory init'ed\n",
    "    parcel_dr = os.path.join('data', 'parcels', 'fs_LR32k_concat')\n",
    "    os.makedirs(parcel_dr, exist_ok=True)\n",
    "    \n",
    "    # Get location\n",
    "    parcel_loc = os.path.join(parcel_dr, f'{parcel_name}.npy')\n",
    "    \n",
    "    # If doesn't exist, try to download\n",
    "    if not os.path.exists(parcel_loc):\n",
    "        parcel_url = f'https://raw.githubusercontent.com/sahahn/parc_scaling/main/parcels/{parcel_name}.npy'\n",
    "        os.system(f'wget -L {parcel_url} -P {parcel_dr}')\n",
    "        \n",
    "    # Load parcel\n",
    "    parcel = np.load(parcel_loc)\n",
    "    \n",
    "    return parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suited-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save some common evaluation parameters in a special object called ProblemSpec\n",
    "ps = bp.ProblemSpec(target='BIS', # Select the target variable we want to predict\n",
    "                    scope='all', # This is set by default, but says use all avaliable features\n",
    "                    n_jobs=8, # The number of multi-proc jobs to use\n",
    "                    random_state=1 # A re-usable random state for this expiriment\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-passage",
   "metadata": {},
   "source": [
    "## Predict Vertex Level\n",
    "\n",
    "We will construct a fairly simple machine learning pipeline to try first. The basic idea is that a ridge regression will be fit and evaluated on the vertex values directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-nowhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting target = BIS\n",
      "Using problem_type = regression\n",
      "Using scope = all (defining a total of 2 features).\n",
      "Evaluating 928 total data points.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f4775cac52449ab6d72b4c51552a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set: (742, 2)\n",
      "Validation Set: (186, 2)\n"
     ]
    }
   ],
   "source": [
    "# This object is responsible for converting from\n",
    "# saved Data Files, to just a flattened numpy / acceptable\n",
    "# input to ML model\n",
    "loader = bp.Loader('identity')\n",
    "\n",
    "# Next, values with be scaled according to robust scaling,\n",
    "# i.e., values are scaled according to the IQR instead of min and max\n",
    "scaler = bp.Scaler('robust', quantile_range=(25, 75))\n",
    "\n",
    "# Get a ridge regression with hyper-parameter search dist.\n",
    "model = get_standard_search_model('ridge')\n",
    "\n",
    "# Lastly, put everything together in a Pipeline\n",
    "# object, which we can pass to evaluate functions\n",
    "pipe = bp.Pipeline(steps=[loader, scaler, model])\n",
    "\n",
    "# Evaluate with default 5 fold CV\n",
    "vertex_results = bp.evaluate(pipe, data, problem_spec=ps)\n",
    "vertex_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-proposal",
   "metadata": {},
   "source": [
    "## Predict ROI level\n",
    "\n",
    "Next, we will consider adding a step where values are converted into mean values per ROI. We will prepare special new Loader objects, as well as use another useful feature of BPt which are the bp.Compare and bp.Option objects. This will allow us to test all of our combinations of interest here at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-burning",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from neurotools.transform.rois import SurfLabels\n",
    "\n",
    "# Load hcp_mmp and random parcel\n",
    "hcp_mmp = load_parcel(parcel_name='hcp_mmp')\n",
    "random_500 = load_parcel(parcel_name='random_500_0')\n",
    "\n",
    "# Put together each option in a special compare wrapper\n",
    "options = bp.Compare([bp.Option(hcp_mmp, name='hcp_mmp'),\n",
    "                      bp.Option(random_500, name='random_500_0')])\n",
    "\n",
    "# Generate an alternate loader from before\n",
    "sl = SurfLabels(options, vectorize=True)\n",
    "compare_loaders = bp.Loader(sl, cache_loc=cache_loc)\n",
    "\n",
    "# Generate same options with model\n",
    "model_options = bp.Compare(['elastic', 'svm'])\n",
    "compare_models = model = get_standard_search_model(model_options)\n",
    "\n",
    "# Put together in pipeline\n",
    "roi_pipe = bp.Pipeline(steps=[compare_loaders, scaler, compare_models])\n",
    "\n",
    "# Evaluate\n",
    "compare_results = bp.evaluate(roi_pipe, data, problem_spec=ps,\n",
    "                              eval_verbose=0, mute_warnings=True)\n",
    "\n",
    "# Show a summary\n",
    "compare_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-floating",
   "metadata": {},
   "source": [
    "## Ensemble of random parcellations\n",
    "\n",
    "Last, but not least, we will show an example on how to generate and test an ensemble over different parcellations. For this option, let's use elastic-net's and a ridge regression as the model responsible for averaging predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_pipe(parcel_name):\n",
    "    \n",
    "    # Load parcel\n",
    "    parcel = load_parcel(parcel_name=parcel_name)\n",
    "    \n",
    "    # Wrap in loader\n",
    "    loader = bp.Loader(SurfLabels(parcel, vectorize=True),\n",
    "                       cache_loc=cache_loc)\n",
    "    \n",
    "    # Get scaler and model\n",
    "    scaler = bp.Scaler('robust', quantile_range=(25, 75))\n",
    "    model = get_standard_search_model('elastic')\n",
    "    \n",
    "    # Return as pipeline\n",
    "    pipe = bp.Pipeline([loader, scaler, model])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-worth",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build each sub ensemble from a different random parcellation with 500 parcels\n",
    "sub_pipes = [get_sub_pipe(parcel_name=f'random_500_{i}') for i in range(5)]\n",
    "\n",
    "# Put together ensemble\n",
    "stacker = get_standard_search_model('elastic')\n",
    "ensemble = bp.Ensemble('stacking', models=sub_pipes, base_model=stacker)\n",
    "\n",
    "ensemble_results1 = bp.evaluate(ensemble, data, problem_spec=ps, mute_warnings=True)\n",
    "ensemble_results1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-state",
   "metadata": {},
   "source": [
    "### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can ensemble over even more parcellations, from even more sizes\n",
    "# at the expense of additionally processing time.\n",
    "sub_pipes = [get_sub_pipe(parcel_name=f'random_500_{i}') for i in range(3)]\n",
    "sub_pipes += [get_sub_pipe(parcel_name=f'random_1000_{i}') for i in range(3)]\n",
    "sub_pipes += [get_sub_pipe(parcel_name=f'random_2000_{i}') for i in range(3)]\n",
    "sub_pipes += [get_sub_pipe(parcel_name=f'random_3000_{i}') for i in range(3)]\n",
    "\n",
    "# Put together ensemble\n",
    "stacker = get_standard_search_model('elastic')\n",
    "ensemble = bp.Ensemble('stacking', models=sub_pipes, base_model=stacker)\n",
    "\n",
    "ensemble_results2 = bp.evaluate(ensemble, data, problem_spec=ps, mute_warnings=True)\n",
    "ensemble_results2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpt",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
