{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "criminal-paris",
   "metadata": {},
   "source": [
    "# Prepare FreeSurfer ROIs Dataset\n",
    "\n",
    "The idea here is to work with freesurfer extracted ROI data in desikan + destr + subcort + wmparc as provided in downloaded:\n",
    "\n",
    "`derivatives/fs_stats/data-*.tsv\n",
    "                      data-cortical_type-aparc.a2009s_measure-*.tsv\n",
    "                      data-cortical_type-aparc_measure-*.tsv\n",
    "                      data-subcortical_type-aseg_measure-*.tsv\n",
    "                      data-subcortical_type-wmparc_measure-*.tsv`\n",
    "                      \n",
    "The purpose of this notebook in particular is for preparing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "artistic-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, abspath\n",
    "import pandas as pd\n",
    "import os\n",
    "import BPt as bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acknowledged-devon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sage/methods_series/ds003097/datasets'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Useful directories\n",
    "main_dr = dirname(dirname(abspath(os.getcwd())))\n",
    "saves_dr = os.path.join(dirname(os.getcwd()), 'datasets')\n",
    "data_dr = os.path.join(main_dr, 'data')\n",
    "deriv_dr = os.path.join(data_dr, 'ds003097', 'derivatives')\n",
    "fs_stats_dr = os.path.join(deriv_dr, 'fs_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specified-phone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-cortical_type-aparc.a2009s_measure-meancurv_hemi-lh.tsv',\n",
       " 'data-cortical_type-aparc_measure-area_hemi-lh.tsv',\n",
       " 'data-cortical_type-aparc_measure-volume_hemi-lh.tsv',\n",
       " 'data-cortical_type-aparc_measure-area_hemi-rh.tsv',\n",
       " 'data-subcortical_type-wmparc_measure-mean_hemi-both.tsv',\n",
       " 'data-cortical_type-aparc_measure-thickness_hemi-lh.tsv',\n",
       " 'data-subcortical_type-aseg_measure-mean_hemi-both.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-volume_hemi-rh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-volume_hemi-lh.tsv',\n",
       " 'data-cortical_type-aparc_measure-thickness_hemi-rh.tsv',\n",
       " 'data-cortical_type-aparc_measure-meancurv_hemi-rh.tsv',\n",
       " 'data-subcortical_type-wmparc_measure-volume_hemi-both.tsv',\n",
       " 'data-cortical_type-aparc_measure-volume_hemi-rh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-meancurv_hemi-rh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-thickness_hemi-lh.tsv',\n",
       " 'data-cortical_type-aparc_measure-meancurv_hemi-lh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-thickness_hemi-rh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-area_hemi-rh.tsv',\n",
       " 'data-subcortical_type-aseg_measure-volume_hemi-both.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-area_hemi-lh.tsv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are all avaliable files, but we likely don't want all, let's apply further filtering\n",
    "files = [file for file in os.listdir(fs_stats_dr) if 'sub-' not in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worse-consultancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-subcortical_type-wmparc_measure-mean_hemi-both.tsv',\n",
       " 'data-subcortical_type-aseg_measure-mean_hemi-both.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-volume_hemi-rh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-volume_hemi-lh.tsv',\n",
       " 'data-subcortical_type-wmparc_measure-volume_hemi-both.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-thickness_hemi-lh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-thickness_hemi-rh.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-area_hemi-rh.tsv',\n",
       " 'data-subcortical_type-aseg_measure-volume_hemi-both.tsv',\n",
       " 'data-cortical_type-aparc.a2009s_measure-area_hemi-lh.tsv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to just destr altas and subcortical\n",
    "files = [file for file in files if 'curv' not in file and (('subcortical' in file) or ('a2009s' in file))]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "medieval-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fs_stats_dr, file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stretch-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(loc):\n",
    "    \n",
    "    # Load as dataframe\n",
    "    data = pd.read_csv(loc, sep='\\t')\n",
    "    name = list(data)[0]\n",
    "    \n",
    "    # Set to correct index\n",
    "    data = data.set_index(list(data)[0])\n",
    "    \n",
    "    # Change index name\n",
    "    data.index.name = 'participant_id'\n",
    "    \n",
    "    # Add name to columns\n",
    "    new_col_names = {col: name + '_' + col for col in list(data)}\n",
    "    data = data.rename(new_col_names, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "circular-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat\n",
    "rois = pd.concat([load(file) for file in files], axis=1)\n",
    "\n",
    "# Drop duplicates\n",
    "rois = rois.loc[:,~rois.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "instructional-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base template dataframe with targets loaded\n",
    "data = bp.read_pickle(os.path.join(saves_dr, 'template.dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "apart-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat and cast to dataset\n",
    "data = bp.Dataset(pd.concat([data, rois], axis=1), targets=list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cooperative-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "data.to_pickle(os.path.join(saves_dr, 'fs_rois.dataset'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpt",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
